// EU AI Act — Annexes I through XIII
// Source: Regulation (EU) 2024/1689, Official Journal of the European Union
// https://eur-lex.europa.eu/eli/reg/2024/1689/oj/eng

export const ANNEXES = [
  {
    number: "I",
    id: 1,
    title: "List of Union Harmonisation Legislation",
    subtitle: "Section A — New Legislative Framework; Section B — Other Union Harmonisation Legislation",
    relatedArticles: [6],
    summary: "Identifies existing EU harmonisation legislation that intersects with the AI Act. If an AI system is a safety component of, or is itself, a product covered by this legislation, the high-risk classification under Article 6(1) applies.",
    sections: [
      {
        title: "Section A — List of Union Harmonisation Legislation Based on the New Legislative Framework",
        items: [
          "1. Directive 2006/42/EC of the European Parliament and of the Council of 17 May 2006 on machinery, and amending Directive 95/16/EC (OJ L 157, 9.6.2006, p. 24).",
          "2. Directive 2009/48/EC of the European Parliament and of the Council of 18 June 2009 on the safety of toys (OJ L 170, 30.6.2009, p. 1).",
          "3. Directive 2013/53/EU of the European Parliament and of the Council of 20 November 2013 on recreational craft and personal watercraft, and repealing Directive 94/25/EC (OJ L 354, 28.12.2013, p. 90).",
          "4. Directive 2014/33/EU of the European Parliament and of the Council of 26 February 2014 on the harmonisation of the laws of the Member States relating to lifts and safety components for lifts (OJ L 96, 29.3.2014, p. 251).",
          "5. Directive 2014/34/EU of the European Parliament and of the Council of 26 February 2014 on the harmonisation of the laws of the Member States relating to equipment and protective systems intended for use in potentially explosive atmospheres (OJ L 96, 29.3.2014, p. 309).",
          "6. Directive 2014/53/EU of the European Parliament and of the Council of 16 April 2014 on the harmonisation of the laws of the Member States relating to the making available on the market of radio equipment, and repealing Directive 1999/5/EC (OJ L 153, 22.5.2014, p. 62).",
          "7. Directive 2014/68/EU of the European Parliament and of the Council of 15 May 2014 on the harmonisation of the laws of the Member States relating to the making available on the market of pressure equipment (OJ L 189, 27.6.2014, p. 164).",
          "8. Regulation (EU) 2016/424 of the European Parliament and of the Council of 9 March 2016 on cableway installations and repealing Directive 2000/9/EC (OJ L 81, 31.3.2016, p. 1).",
          "9. Regulation (EU) 2016/425 of the European Parliament and of the Council of 9 March 2016 on personal protective equipment and repealing Council Directive 89/686/EEC (OJ L 81, 31.3.2016, p. 51).",
          "10. Regulation (EU) 2016/426 of the European Parliament and of the Council of 9 March 2016 on appliances burning gaseous fuels and repealing Directive 2009/142/EC (OJ L 81, 31.3.2016, p. 99).",
          "11. Regulation (EU) 2017/745 of the European Parliament and of the Council of 5 April 2017 on medical devices, amending Directive 2001/83/EC, Regulation (EC) No 178/2002 and Regulation (EC) No 1223/2009 and repealing Council Directives 90/385/EEC and 93/42/EEC (OJ L 117, 5.5.2017, p. 1).",
          "12. Regulation (EU) 2017/746 of the European Parliament and of the Council of 5 April 2017 on in vitro diagnostic medical devices and repealing Directive 98/79/EC and Commission Decision 2010/227/EU (OJ L 117, 5.5.2017, p. 176)."
        ]
      },
      {
        title: "Section B — List of Other Union Harmonisation Legislation",
        items: [
          "1. Regulation (EC) No 300/2008 of the European Parliament and of the Council of 11 March 2008 on common rules in the field of civil aviation security, and repealing Regulation (EC) No 2320/2002.",
          "2. Regulation (EU) No 168/2013 of the European Parliament and of the Council of 15 January 2013 on the approval and market surveillance of two- or three-wheel vehicles and quadricycles.",
          "3. Regulation (EU) No 167/2013 of the European Parliament and of the Council of 5 February 2013 on the approval and market surveillance of agricultural and forestry vehicles.",
          "4. Directive 2014/90/EU of the European Parliament and of the Council of 23 July 2014 on marine equipment and repealing Council Directive 96/98/EC.",
          "5. Directive (EU) 2016/797 of the European Parliament and of the Council of 11 May 2016 on the interoperability of the rail system within the European Union.",
          "6. Regulation (EU) 2018/858 of the European Parliament and of the Council of 30 May 2018 on the approval and market surveillance of motor vehicles and their trailers, and of systems, components and separate technical units intended for such vehicles.",
          "7. Regulation (EU) 2018/1139 of the European Parliament and of the Council of 4 July 2018 on common rules in the field of civil aviation and establishing a European Union Aviation Safety Agency, including as regards unmanned aircraft systems.",
          "8. Regulation (EU) 2019/2144 of the European Parliament and of the Council of 27 November 2019 on type-approval requirements for motor vehicles and their trailers, and systems, components and separate technical units intended for such vehicles, as regards their general safety and the protection of vehicle occupants and vulnerable road users."
        ]
      }
    ]
  },
  {
    number: "II",
    id: 2,
    title: "List of Criminal Offences Referred to in Article 5(1), First Subparagraph, Point (h)(iii)",
    subtitle: "Criminal offences for which real-time remote biometric identification may be permitted",
    relatedArticles: [5],
    summary: "Defines the scope of serious criminal offences for which certain real-time remote biometric identification systems may be permitted, subject to strict conditions under Article 5.",
    sections: [
      {
        title: "Criminal Offences",
        items: [
          "1. Terrorism.",
          "2. Trafficking in human beings.",
          "3. Sexual exploitation of children and child pornography.",
          "4. Illicit trafficking in narcotic drugs or psychotropic substances.",
          "5. Illicit trafficking in weapons, munitions or explosives.",
          "6. Murder, grievous bodily injury.",
          "7. Illicit trade in human organs or tissue.",
          "8. Illicit trafficking in nuclear or radioactive materials.",
          "9. Kidnapping, illegal restraint or hostage-taking.",
          "10. Crimes within the jurisdiction of the International Criminal Court.",
          "11. Unlawful seizure of aircraft or ships.",
          "12. Rape.",
          "13. Environmental crime.",
          "14. Organised or armed robbery.",
          "15. Sabotage.",
          "16. Participation in a criminal organisation involved in one or more of the offences listed above."
        ]
      }
    ]
  },
  {
    number: "III",
    id: 3,
    title: "High-Risk AI Systems Referred to in Article 6(2)",
    subtitle: "Standalone classification of high-risk AI systems by area of use",
    relatedArticles: [6, 7, 27, 43],
    summary: "Provides the standalone classification of high-risk AI systems, independent of product safety legislation. These are systems whose use in these eight areas poses significant risks to fundamental rights, health, or safety.",
    sections: [
      {
        title: "1. Biometrics",
        preamble: "Insofar as their use is permitted under relevant Union or national law:",
        items: [
          "(a) AI systems intended to be used for remote biometric identification systems, excluding AI systems intended to be used for biometric verification the sole purpose of which is to confirm that a specific natural person is the person he or she claims to be.",
          "(b) AI systems intended to be used for biometric categorisation, according to sensitive or protected attributes or characteristics based on the inference of those attributes or characteristics.",
          "(c) AI systems intended to be used for emotion recognition."
        ]
      },
      {
        title: "2. Critical Infrastructure",
        items: [
          "AI systems intended to be used as safety components in the management and operation of critical digital infrastructure, road traffic, or in the supply of water, gas, heating or electricity."
        ]
      },
      {
        title: "3. Education and Vocational Training",
        items: [
          "(a) AI systems intended to be used for determining access or admission or for assigning natural persons to educational and vocational training institutions at all levels.",
          "(b) AI systems intended to be used for evaluating learning outcomes, including when those outcomes are used to steer the learning process.",
          "(c) AI systems intended to be used for the purpose of assessing the appropriate level of education that an individual will receive or will be able to access, in the context of or within educational and vocational training institutions at all levels.",
          "(d) AI systems intended to be used for monitoring and detecting prohibited behaviour of students during tests."
        ]
      },
      {
        title: "4. Employment, Workers Management and Access to Self-Employment",
        items: [
          "(a) AI systems intended to be used for the recruitment or selection of natural persons, in particular for publishing targeted job advertisements, screening or filtering applications, and evaluating candidates.",
          "(b) AI systems intended to be used for making decisions affecting terms of work-related relationships, promotion, termination of work-related contractual relationships, for allocating tasks based on individual behaviour, personal traits or characteristics, and for monitoring or evaluating performance and behaviour of persons in such relationships."
        ]
      },
      {
        title: "5. Access to and Enjoyment of Essential Private Services and Essential Public Services and Benefits",
        items: [
          "(a) AI systems intended to be used by public authorities or on behalf of public authorities to evaluate the eligibility of natural persons for essential public assistance benefits and services, including healthcare services, as well as to grant, reduce, revoke, or reclaim such benefits and services.",
          "(b) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with the exception of AI systems used for the purpose of detecting financial fraud.",
          "(c) AI systems intended to be used for risk assessment and pricing in relation to natural persons in the case of life and health insurance.",
          "(d) AI systems intended to be used to evaluate and classify emergency calls by natural persons or to dispatch, or to establish priority in the dispatching of, emergency first response services, including by police, firefighters and medical aid, as well as of emergency healthcare patient triage systems."
        ]
      },
      {
        title: "6. Law Enforcement",
        preamble: "Insofar as their use is permitted under relevant Union or national law:",
        items: [
          "(a) AI systems intended to be used by or on behalf of law enforcement authorities, or by Union institutions, bodies, offices or agencies in support of law enforcement authorities or on their behalf, to assess the risk of a natural person becoming the victim of criminal offences.",
          "(b) AI systems intended to be used by or on behalf of law enforcement authorities or by Union institutions, bodies, offices or agencies in support of law enforcement authorities as polygraphs or similar tools.",
          "(c) AI systems intended to be used by or on behalf of law enforcement authorities or by Union institutions, bodies, offices or agencies in support of law enforcement authorities to evaluate the reliability of evidence in the course of investigation or prosecution of criminal offences.",
          "(d) AI systems intended to be used by or on behalf of law enforcement authorities or by Union institutions, bodies, offices or agencies in support of law enforcement authorities for assessing the risk of a natural person offending or reoffending not solely on the basis of the profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016/680, or to assess personality traits and characteristics or past criminal behaviour of natural persons or groups.",
          "(e) AI systems intended to be used by or on behalf of law enforcement authorities or by Union institutions, bodies, offices or agencies in support of law enforcement authorities for profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016/680 in the course of detection, investigation or prosecution of criminal offences."
        ]
      },
      {
        title: "7. Migration, Asylum and Border Control Management",
        preamble: "Insofar as their use is permitted under relevant Union or national law:",
        items: [
          "(a) AI systems intended to be used by or on behalf of competent public authorities or by Union institutions, bodies, offices or agencies as polygraphs or similar tools.",
          "(b) AI systems intended to be used by or on behalf of competent public authorities or by Union institutions, bodies, offices or agencies to assess a risk, including a security risk, a risk of irregular migration, or a health risk, posed by a natural person who intends to enter or has entered the territory of a Member State.",
          "(c) AI systems intended to be used by or on behalf of competent public authorities or by Union institutions, bodies, offices or agencies to assist competent public authorities for the examination of applications for asylum, visa or residence permits and for associated complaints with regard to the eligibility of the natural persons applying for a status, including related assessments of the reliability of evidence.",
          "(d) AI systems intended to be used by or on behalf of competent public authorities or by Union institutions, bodies, offices or agencies, in the context of migration, asylum and border control management, for the purpose of detecting, recognising or identifying natural persons, with the exception of verification of travel documents."
        ]
      },
      {
        title: "8. Administration of Justice and Democratic Processes",
        items: [
          "(a) AI systems intended to be used by a judicial authority or on their behalf to assist a judicial authority in researching and interpreting facts and the law and in applying the law to a concrete set of facts, or to be used in a similar way in alternative dispute resolution.",
          "(b) AI systems intended to be used for influencing the outcome of an election or referendum or the voting behaviour of natural persons in the exercise of their vote in elections or referenda. This does not include AI systems to the output of which natural persons are not directly exposed, such as tools used to organise, optimise and structure political campaigns from an administrative and logistic point of view."
        ]
      }
    ]
  },
  {
    number: "IV",
    id: 4,
    title: "Technical Documentation Referred to in Article 11(1)",
    subtitle: "Minimum content required for technical documentation of high-risk AI systems",
    relatedArticles: [11, 17],
    summary: "Defines the minimum content required for the technical documentation of high-risk AI systems. Must be drawn up before the system is placed on the market or put into service and kept up to date.",
    sections: [
      {
        title: "Technical Documentation Requirements",
        preamble: "The technical documentation referred to in Article 11(1) shall contain at least the following information, as applicable to the relevant AI system:",
        items: [
          "1. A general description of the AI system including: (a) its intended purpose, the name of the provider and the version of the system reflecting its relation to previous versions; (b) how the AI system interacts or can be used to interact with hardware or software, including with other AI systems, that are not part of the AI system itself, where applicable; (c) the versions of relevant software or firmware and any requirement related to version update; (d) the description of all the forms in which the AI system is placed on the market or put into service, such as software packages embedded into hardware, downloads, or APIs; (e) the description of the hardware on which the AI system is intended to run; (f) where the AI system is a component of products, photographs or illustrations showing external features, marking and internal layout of those products; (g) a basic description of the user-interface provided to the deployer; (h) instructions of use for the deployer and a basic description of the user-interface provided to the deployer, where applicable.",
          "2. A detailed description of the elements of the AI system and of the process for its development, including: (a) the methods and steps performed for the development of the AI system, including, where relevant, recourse to pre-trained systems or tools provided by third parties and how those have been used, integrated or modified by the provider; (b) the design specifications of the system, namely the general logic of the AI system and of the algorithms; the key design choices including the rationale and assumptions made, also with regard to persons or groups of persons on which the system is intended to be used; the main classification choices; what the system is designed to optimise for, and the relevance of the different parameters; the description of the expected output and output quality of the system; the decisions about any possible trade-off made regarding the technical solutions adopted to comply with the requirements set out in Chapter III, Section 2; (c) the description of the system architecture explaining how software components build on or feed into each other and integrate into the overall processing; the computational resources used to develop, train, test and validate the AI system; (d) where relevant, the data requirements in terms of datasheets describing the training methodologies and techniques and the training data sets used, including a general description of these data sets, information on their provenance, scope and main characteristics; how the data was obtained and selected; labelling procedures (e.g. for supervised learning), data cleaning methodologies (e.g. outliers detection); (e) assessment of the human oversight measures needed in accordance with Article 14, including an assessment of the technical measures needed to facilitate the interpretation of the outputs of AI systems by the deployers, in accordance with Article 13(3), point (d); (f) where applicable, a detailed description of pre-determined changes to the AI system and its performance, together with all the relevant information related to the technical solutions adopted to ensure continuous compliance of the AI system with the relevant requirements set out in Chapter III, Section 2; (g) the validation and testing procedures used, including information on the validation and testing data used and their main characteristics; metrics used to measure accuracy, robustness and compliance with other relevant requirements set out in Chapter III, Section 2, as well as potentially discriminatory impacts; test logs and all test reports dated and signed by the responsible persons, including with regard to pre-determined changes as referred to in point (f); (h) cybersecurity measures put in place.",
          "3. Detailed information about the monitoring, functioning and control of the AI system, in particular with regard to: its capabilities and limitations in performance, including the degrees of accuracy for specific persons or groups of persons on which the system is intended to be used and the overall expected level of accuracy in relation to its intended purpose; the foreseeable unintended outcomes and sources of risks to health and safety, fundamental rights and discrimination in view of the intended purpose of the AI system; the human oversight measures needed in accordance with Article 14, including the technical measures put in place to facilitate the interpretation of the outputs of AI systems by the deployers; the specifications on input data, as appropriate.",
          "4. A description of the appropriateness of the performance metrics for the specific AI system.",
          "5. A detailed description of the risk management system in accordance with Article 9.",
          "6. A description of the relevant changes made by the provider to the system throughout its lifecycle.",
          "7. A list of the harmonised standards applied in full or in part, the references of which have been published in the Official Journal of the European Union; where no such harmonised standards have been applied, a detailed description of the solutions adopted to meet the requirements set out in Chapter III, Section 2, including a list of other relevant standards and technical specifications applied.",
          "8. A copy of the EU declaration of conformity referred to in Article 47.",
          "9. A detailed description of the system in place to evaluate the AI system performance in the post-market phase in accordance with Article 72, including the post-market monitoring plan referred to in Article 72(3)."
        ]
      }
    ]
  },
  {
    number: "V",
    id: 5,
    title: "EU Declaration of Conformity",
    subtitle: "Mandatory content of the EU Declaration of Conformity for high-risk AI systems",
    relatedArticles: [47],
    summary: "Specifies the mandatory content of the EU Declaration of Conformity referenced in Article 47, which is the formal statement by a provider that a high-risk AI system meets regulatory requirements.",
    sections: [
      {
        title: "Required Content",
        preamble: "The EU declaration of conformity referred to in Article 47 shall contain all of the following information:",
        items: [
          "1. AI system name and type and any additional unambiguous reference allowing the identification and traceability of the AI system.",
          "2. The name and address of the provider or, where applicable, of their authorised representative.",
          "3. A statement that the EU declaration of conformity referred to in Article 47 is issued under the sole responsibility of the provider.",
          "4. A statement that the AI system is in conformity with this Regulation and, if applicable, with any other relevant Union law that provides for the issuing of an EU declaration of conformity.",
          "5. Where an AI system involves the processing of personal data, a statement that that AI system complies with Regulations (EU) 2016/679 and (EU) 2018/1725 and Directive (EU) 2016/680.",
          "6. References to any relevant harmonised standards used or any other common specification in relation to which conformity is declared.",
          "7. Where applicable, the name and identification number of the notified body, a description of the conformity assessment procedure performed, and identification of the certificate issued.",
          "8. The place and date of issue of the declaration, the name and function of the person who signed it, as well as an indication for, or on behalf of whom, that person signed, a signature."
        ]
      }
    ]
  },
  {
    number: "VI",
    id: 6,
    title: "Conformity Assessment Procedure Based on Internal Control",
    subtitle: "Self-assessment route for providers of high-risk AI systems",
    relatedArticles: [43],
    summary: "Defines the self-assessment route for providers of high-risk AI systems that do not require third-party (notified body) involvement. This is the simpler of the two conformity assessment paths.",
    sections: [
      {
        title: "Internal Control Procedure",
        items: [
          "1. The conformity assessment procedure based on internal control is the conformity assessment procedure based on points 2, 3 and 4.",
          "2. The provider verifies that the established quality management system is in compliance with the requirements of Article 17.",
          "3. The provider examines the information contained in the technical documentation in order to assess the compliance of the AI system with the relevant essential requirements set out in Chapter III, Section 2.",
          "4. The provider also verifies that the design and development process of the AI system and its post-market monitoring as referred to in Article 72 is consistent with the technical documentation."
        ]
      }
    ]
  },
  {
    number: "VII",
    id: 7,
    title: "Conformity Based on an Assessment of the Quality Management System and an Assessment of the Technical Documentation",
    subtitle: "Conformity assessment involving a notified body",
    relatedArticles: [43, 17],
    summary: "Defines the conformity assessment route involving a notified body that evaluates both the provider's quality management system and the technical documentation for each AI system. This is the more rigorous conformity path, required for certain high-risk AI systems (particularly those in Annex III areas 1, 6, 7, and 8).",
    sections: [
      {
        title: "Overview",
        items: [
          "1. Conformity based on an assessment of the quality management system and an assessment of the technical documentation is the conformity assessment procedure based on points 2 to 5."
        ]
      },
      {
        title: "2. Quality Management System Assessment — Overview",
        items: [
          "The approved quality management system for the design, development and testing of AI systems pursuant to Article 17 shall be examined in accordance with point 3 and shall be subject to surveillance as specified in point 5. The technical documentation of the AI system shall be examined in accordance with point 4."
        ]
      },
      {
        title: "3. Quality Management System",
        items: [
          "3.1. The application of the provider shall include: (a) the name and address of the provider and, if the application is lodged by the authorised representative, their name and address as well; (b) the list of AI systems covered under the same quality management system; (c) the technical documentation for each AI system covered under the same quality management system; (d) the documentation concerning the quality management system which shall address all the aspects listed under Article 17; (e) a description of the procedures in place to ensure that the quality management system remains adequate and effective; (f) a written declaration that the same application has not been lodged with any other notified body.",
          "3.2. The quality management system shall be assessed by the notified body, which shall determine whether it satisfies the requirements referred to in Article 17. The decision shall be notified to the provider or its authorised representative. The notification shall contain the conclusions of the assessment of the quality management system and the reasoned assessment decision.",
          "3.3. The quality management system as approved shall continue to be implemented and maintained by the provider so that it remains adequate and efficient.",
          "3.4. Any intended change to the approved quality management system or the list of AI systems covered by it shall be brought to the attention of the notified body by the provider. The proposed changes shall be examined by the notified body, which shall decide whether the modified quality management system continues to satisfy the requirements referred to in point 3.2 or whether a reassessment is necessary. The notified body shall notify the provider of its decision. The notification shall contain the conclusions of the examination of the changes and the reasoned assessment decision."
        ]
      },
      {
        title: "4. Control of the Technical Documentation",
        items: [
          "4.1. In addition to the application referred to in point 3, the provider shall lodge an application with the notified body of its choice for the assessment of the technical documentation relating to the AI system which the provider plans to place on the market or put into service and which is covered by the quality management system referred to under point 3.",
          "4.2. The application shall include: (a) the name and address of the provider; (b) a written declaration that the same application has not been lodged with any other notified body; (c) the technical documentation referred to in Annex IV.",
          "4.3. The technical documentation shall be examined by the notified body. Where relevant, and limited to what is necessary to fulfil its tasks, the notified body shall be granted full access to the training, validation, and testing data sets used, including, where appropriate and subject to security safeguards, through application programming interfaces (API) or other relevant technical means and tools enabling remote access.",
          "4.4. In examining the technical documentation, the notified body may require that the provider supply further evidence or carry out further tests so as to enable a proper assessment of the conformity of the AI system with the requirements set out in Chapter III, Section 2. Whenever the notified body is not satisfied with the tests carried out by the provider, the notified body shall directly carry out adequate tests, as appropriate.",
          "4.5. Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Chapter III, Section 2, after all other reasonable means to verify conformity have been exhausted and have proven to be insufficient, and upon a reasoned request, the notified body shall also be granted access to the training and trained models of the AI system, including its relevant parameters. Such access shall be subject to existing Union law on the protection of intellectual property and trade secrets.",
          "4.6. The decision of the notified body shall be notified to the provider or its authorised representative. The notification shall contain the conclusions of the assessment of the technical documentation and the reasoned assessment decision. Where the AI system is in conformity with the requirements set out in Chapter III, Section 2, the notified body shall issue a Union technical documentation assessment certificate. The certificate shall indicate the name and address of the provider, the conclusions of the examination, the conditions (if any) for its validity and the data necessary for the identification of the AI system. Where the AI system is not in conformity with the requirements set out in Chapter III, Section 2, the notified body shall refuse to issue a Union technical documentation assessment certificate and shall inform the applicant accordingly, giving detailed reasons for its refusal. Where the AI system does not meet the requirement relating to the data used to train it, re-training of the AI system will be needed prior to the application for a new conformity assessment. In this case, the reasoned assessment decision of the notified body refusing to issue the Union technical documentation assessment certificate shall contain specific considerations on the quality data used to train the AI system, in particular on the reasons for non-compliance.",
          "4.7. Any change to the AI system that could affect the compliance of the AI system with the requirements or its intended purpose shall be assessed by the notified body which issued the Union technical documentation assessment certificate. The provider shall inform such notified body of its intention to introduce any of the abovementioned changes or if it becomes otherwise aware of the occurrence of such changes. The intended changes shall be assessed by the notified body, which shall decide whether those changes require a new conformity assessment in accordance with Article 43(4) or whether they could be addressed by means of a supplement to the Union technical documentation assessment certificate. In the latter case, the notified body shall assess the changes, notify the provider of its decision and, where the changes are approved, issue to the provider a supplement to the Union technical documentation assessment certificate."
        ]
      },
      {
        title: "5. Surveillance of the Approved Quality Management System",
        items: [
          "5.1. The purpose of the surveillance carried out by the notified body referred to in point 3 is to make sure that the provider duly complies with the terms and conditions of the approved quality management system.",
          "5.2. For assessment purposes, the provider shall allow the notified body to access the premises where the design, development, testing of the AI systems is taking place. The provider shall further share with the notified body all necessary information.",
          "5.3. The notified body shall carry out periodic audits to make sure that the provider maintains and applies the quality management system and shall provide the provider with an audit report. In the context of those audits, the notified body may carry out additional tests of the AI systems for which a Union technical documentation assessment certificate was issued."
        ]
      }
    ]
  },
  {
    number: "VIII",
    id: 8,
    title: "Information to be Submitted upon the Registration of High-Risk AI Systems in Accordance with Article 49",
    subtitle: "Registration information for providers and deployers",
    relatedArticles: [49],
    summary: "Specifies what information providers and deployers must submit to the EU database for high-risk AI systems. Divided into three sections covering provider information, non-high-risk designation information, and deployer information.",
    sections: [
      {
        title: "Section A — Information to be Submitted by Providers of High-Risk AI Systems in Accordance with Article 49(1)",
        preamble: "The following information shall be provided and thereafter kept up to date with regard to high-risk AI systems to be registered in accordance with Article 49(1):",
        items: [
          "1. The name, address and contact details of the provider.",
          "2. Where submission of information is carried out by another person on behalf of the provider, the name, address and contact details of that person.",
          "3. The name, address and contact details of the authorised representative, where applicable.",
          "4. The AI system trade name and any additional unambiguous reference allowing the identification and traceability of the AI system.",
          "5. A description of the intended purpose of the AI system and of the components and functions supported through this AI system.",
          "6. A basic and concise description of the information used by the system (data, inputs) and its operating logic.",
          "7. The status of the AI system (on the market, or in service; no longer placed on the market/in service, recalled).",
          "8. The type, number and expiry date of the certificate issued by the notified body and the name or identification number of that notified body, where applicable.",
          "9. A scanned copy of the certificate referred to in point 8, where applicable.",
          "10. Any Member States in which the AI system has been placed on the market, put into service or made available in the Union.",
          "11. A copy of the EU declaration of conformity referred to in Article 47.",
          "12. Electronic instructions for use; this information shall not be provided for high-risk AI systems in the areas of law enforcement or migration, asylum and border control management referred to in Annex III, points 1, 6, 7 and 8.",
          "13. A URL for additional information (optional)."
        ]
      },
      {
        title: "Section B — Information to be Submitted by Providers of AI Systems Referred to in Article 49(2)",
        preamble: "The following information shall be provided and thereafter kept up to date with regard to AI systems to be registered in accordance with Article 49(2):",
        items: [
          "1. The name, address and contact details of the provider.",
          "2. Where submission of information is carried out by another person on behalf of the provider, the name, address and contact details of that person.",
          "3. The name, address and contact details of the authorised representative, where applicable.",
          "4. The AI system trade name and any additional unambiguous reference allowing the identification and traceability of the AI system.",
          "5. A description of the intended purpose of the AI system.",
          "6. The condition or conditions under Article 6(3) based on which the AI system is considered to be not high-risk.",
          "7. A short summary of the grounds on which the AI system is considered to be not high-risk in application of the procedure under Article 6(3).",
          "8. The status of the AI system (on the market, or in service; no longer placed on the market/in service, recalled).",
          "9. Any Member States in which the AI system has been placed on the market, put into service or made available in the Union."
        ]
      },
      {
        title: "Section C — Information to be Submitted by Deployers of High-Risk AI Systems in Accordance with Article 49(3)",
        preamble: "The following information shall be provided and thereafter kept up to date with regard to high-risk AI systems to be registered in accordance with Article 49(3):",
        items: [
          "1. The name, address and contact details of the deployer.",
          "2. The name, address and contact details of the person submitting information on behalf of the deployer.",
          "3. The URL of the entry of the AI system in the EU database by its provider.",
          "4. A summary of the findings of the fundamental rights impact assessment carried out in accordance with Article 27.",
          "5. A summary of the data protection impact assessment carried out in accordance with Article 35 of Regulation (EU) 2016/679 or Article 27 of Directive (EU) 2016/680 as specified in Article 26(9) of this Regulation, where applicable."
        ]
      }
    ]
  },
  {
    number: "IX",
    id: 9,
    title: "Information to be Submitted upon the Registration of High-Risk AI Systems Listed in Annex III in Relation to Testing in Real World Conditions in Accordance with Article 60",
    subtitle: "Registration information for real-world testing of high-risk AI systems",
    relatedArticles: [60],
    summary: "Specifies information required when registering high-risk AI systems listed in Annex III that are undergoing real-world testing conditions, ensuring transparency and traceability for experimental deployments.",
    sections: [
      {
        title: "Required Information",
        preamble: "The following information shall be provided and thereafter kept up to date with regard to testing in real world conditions to be registered in accordance with Article 60:",
        items: [
          "1. A Union-wide unique single identification number of the testing in real world conditions.",
          "2. The name and contact details of the provider or prospective provider and of the deployers involved in the testing in real world conditions.",
          "3. A brief description of the AI system, its intended purpose, and other information necessary for the identification of the system.",
          "4. A summary of the main characteristics of the plan for testing in real world conditions.",
          "5. Information on the suspension or termination of the testing in real world conditions."
        ]
      }
    ]
  },
  {
    number: "X",
    id: 10,
    title: "Union Legislative Acts on Large-Scale IT Systems in the Area of Freedom, Security and Justice",
    subtitle: "EU legislative acts governing major EU-wide information technology systems",
    relatedArticles: [6],
    summary: "Lists the EU legislative acts governing the major EU-wide information technology systems in the justice and security domain. AI systems that are components of these IT systems are classified as high-risk under Article 6(2) when listed in Annex III.",
    sections: [
      {
        title: "1. Schengen Information System",
        items: [
          "(a) Regulation (EU) 2018/1860 of the European Parliament and of the Council of 28 November 2018 on the use of the Schengen Information System for the return of illegally staying third-country nationals (OJ L 312, 7.12.2018, p. 1).",
          "(b) Regulation (EU) 2018/1861 of the European Parliament and of the Council of 28 November 2018 on the establishment, operation and use of the Schengen Information System (SIS) in the field of border checks, and amending the Convention implementing the Schengen Agreement, and amending and repealing Regulation (EC) No 1987/2006 (OJ L 312, 7.12.2018, p. 14).",
          "(c) Regulation (EU) 2018/1862 of the European Parliament and of the Council of 28 November 2018 on the establishment, operation and use of the Schengen Information System (SIS) in the field of police cooperation and judicial cooperation in criminal matters, amending and repealing Council Decision 2007/533/JHA, and repealing Regulation (EC) No 1986/2006 of the European Parliament and of the Council and Commission Decision 2010/261/EU (OJ L 312, 7.12.2018, p. 56)."
        ]
      },
      {
        title: "2. Visa Information System",
        items: [
          "(a) Regulation (EU) 2021/1133 of the European Parliament and of the Council of 7 July 2021 amending Regulations (EU) No 603/2013, (EU) 2016/794, (EU) 2018/1862, (EU) 2019/816 and (EU) 2019/818 as regards the establishment of the conditions for accessing other EU information systems for the purposes of the Visa Information System (OJ L 248, 13.7.2021, p. 1).",
          "(b) Regulation (EU) 2021/1134 of the European Parliament and of the Council of 7 July 2021 amending Regulations (EC) No 767/2008, (EC) No 810/2009, (EU) 2017/2226, (EU) 2018/1240, (EU) 2018/1860, (EU) 2018/1861 and (EU) 2019/817 of the European Parliament and of the Council and Council Decision 2004/512/EC and Council Decision 2008/633/JHA, as regards the reform of the Visa Information System (OJ L 248, 13.7.2021, p. 11)."
        ]
      },
      {
        title: "3. Eurodac",
        items: [
          "Regulation (EU) 2024/1358 of the European Parliament and of the Council of 14 May 2024 on the establishment of 'Eurodac' for the comparison of biometric data in order to effectively apply Regulations (EU) 2024/1315 and (EU) 2024/1350 of the European Parliament and of the Council and Council Directive 2001/55/EC and to identify illegally staying third-country nationals and stateless persons and on requests for the comparison with Eurodac data by Member States' law enforcement authorities and Europol for law enforcement purposes, amending Regulations (EU) 2018/1240 and (EU) 2019/818 of the European Parliament and of the Council and repealing Regulation (EU) No 603/2013 of the European Parliament and of the Council (OJ L, 2024/1358, 22.5.2024)."
        ]
      },
      {
        title: "4. Entry/Exit System",
        items: [
          "Regulation (EU) 2017/2226 of the European Parliament and of the Council of 30 November 2017 establishing an Entry/Exit System (EES) to register entry and exit data and refusal of entry data of third-country nationals crossing the external borders of the Member States and determining the conditions for access to the EES for law enforcement purposes, and amending the Convention implementing the Schengen Agreement and Regulations (EC) No 767/2008 and (EU) No 1077/2011 (OJ L 327, 9.12.2017, p. 20)."
        ]
      },
      {
        title: "5. European Travel Information and Authorisation System",
        items: [
          "(a) Regulation (EU) 2018/1240 of the European Parliament and of the Council of 12 September 2018 establishing a European Travel Information and Authorisation System (ETIAS) and amending Regulations (EU) No 1077/2011, (EU) No 515/2014, (EU) 2016/399, (EU) 2016/1624 and (EU) 2017/2226 (OJ L 236, 19.9.2018, p. 1).",
          "(b) Regulation (EU) 2018/1241 of the European Parliament and of the Council of 12 September 2018 amending Regulation (EU) 2016/794 for the purpose of establishing a European Travel Information and Authorisation System (ETIAS) (OJ L 236, 19.9.2018, p. 72)."
        ]
      },
      {
        title: "6. European Criminal Records Information System on Third-Country Nationals and Stateless Persons",
        items: [
          "Regulation (EU) 2019/816 of the European Parliament and of the Council of 17 April 2019 establishing a centralised system for the identification of Member States holding conviction information on third-country nationals and stateless persons (ECRIS-TCN) to supplement the European Criminal Records Information System and amending Regulation (EU) 2018/1726 (OJ L 135, 22.5.2019, p. 1)."
        ]
      },
      {
        title: "7. Interoperability",
        items: [
          "(a) Regulation (EU) 2019/817 of the European Parliament and of the Council of 20 May 2019 on establishing a framework for interoperability between EU information systems in the field of borders and visa and amending Regulations (EC) No 767/2008, (EU) 2016/399, (EU) 2017/2226, (EU) 2018/1240, (EU) 2018/1726 and (EU) 2018/1861 of the European Parliament and of the Council and Council Decisions 2004/512/EC and 2008/633/JHA (OJ L 135, 22.5.2019, p. 27).",
          "(b) Regulation (EU) 2019/818 of the European Parliament and of the Council of 20 May 2019 on establishing a framework for interoperability between EU information systems in the field of police and judicial cooperation, asylum and migration and amending Regulations (EU) 2018/1726, (EU) 2018/1862 and (EU) 2019/816 (OJ L 135, 22.5.2019, p. 85)."
        ]
      }
    ]
  },
  {
    number: "XI",
    id: 11,
    title: "Technical Documentation Referred to in Article 53(1), Point (a) — Technical Documentation for Providers of General-Purpose AI Models",
    subtitle: "Documentation requirements for GPAI model providers",
    relatedArticles: [53],
    summary: "Specifies the technical documentation that providers of general-purpose AI (GPAI) models must draw up and make available to the AI Office and national competent authorities.",
    sections: [
      {
        title: "Section 1 — Information to be Provided by All Providers of General-Purpose AI Models",
        items: [
          "1. A general description of the general-purpose AI model including: (a) the tasks that the model is intended to perform and the type and nature of AI systems into which it can be integrated; (b) the acceptable use policies applicable; (c) the date of release and methods of distribution; (d) the architecture and number of parameters; (e) modality (e.g. text, image) and format of inputs and outputs; (f) the licence.",
          "2. A detailed description of the elements of the model and of the process for its development, including: (a) the technical means (e.g. instructions for use, infrastructure, tools) required for the general-purpose AI model to be integrated into AI systems; (b) the design specifications of the model and training process, including training methodologies and techniques, the key design choices including the rationale and assumptions made; what the model is designed to optimise for and the relevance of the different parameters, as applicable; (c) information on the data used for training, testing and validation, where applicable, including the type and provenance of data and curation methodologies (e.g. cleaning, filtering, etc.), the number of data points, their scope and main characteristics; how the data was obtained and selected as well as all other measures to detect the unsuitability of data sources and methods to detect identifiable biases, where applicable; (d) the computational resources used to train the model (e.g. number of floating point operations), training time, and other relevant details related to the training; (e) known or estimated energy consumption of the model. With regard to point (e), where the energy consumption of the model is unknown, the energy consumption may be based on information about computational resources used."
        ]
      },
      {
        title: "Section 2 — Additional Information to be Provided by Providers of General-Purpose AI Models with Systemic Risk",
        items: [
          "1. A detailed description of the evaluation strategies, including evaluation results, on the basis of available public evaluation protocols and tools or otherwise of other evaluation methodologies. Evaluation strategies shall include evaluation criteria, metrics and the methodology on the identification of limitations.",
          "2. Where applicable, a detailed description of the measures put in place for the purpose of conducting internal and/or external adversarial testing (e.g. red teaming), model adaptations, including alignment and fine-tuning.",
          "3. Where applicable, a detailed description of the system architecture explaining how software components build on or feed into each other and integrate into the overall processing."
        ]
      }
    ]
  },
  {
    number: "XII",
    id: 12,
    title: "Transparency Information Referred to in Article 53(1), Point (b) — Technical Documentation for Providers of General-Purpose AI Models to Downstream Providers that Integrate the Model into Their AI System",
    subtitle: "Transparency obligations for GPAI model providers to downstream providers",
    relatedArticles: [53],
    summary: "Specifies what technical documentation GPAI model providers must share with downstream providers who integrate the model into their own AI systems, to enable understanding, compliance, and proper integration.",
    sections: [
      {
        title: "Required Information",
        preamble: "The technical documentation referred to in Article 53(1), point (b) shall contain at least the following information, as applicable to the size and risk profile of the model:",
        items: [
          "1. A general description of the general-purpose AI model including: (a) the tasks that the model is intended to perform and the type and nature of AI systems into which it can be integrated; (b) the acceptable use policies applicable; (c) the date of release and methods of distribution; (d) how the model interacts or can be used to interact with hardware or software that is not part of the model itself, where applicable; (e) the versions of relevant software related to the use of the general-purpose AI model, where applicable; (f) the architecture and number of parameters; (g) modality (e.g. text, image) and format of inputs and outputs; (h) the licence for the model.",
          "2. A description of the elements of the model and of the process for its development, including: (a) the technical means (e.g. instructions for use, infrastructure, tools) required for the general-purpose AI model to be integrated into AI systems; (b) the modality (e.g. text, image) and format of the inputs and outputs and their maximum size (e.g. context window length, etc.); (c) information on the data used for training, testing and validation, where applicable, including the type and provenance of data and curation methodologies."
        ]
      }
    ]
  },
  {
    number: "XIII",
    id: 13,
    title: "Criteria for the Designation of General-Purpose AI Models with Systemic Risk Referred to in Article 51",
    subtitle: "Evaluation criteria for GPAI models with systemic risk",
    relatedArticles: [51],
    summary: "Establishes the criteria the Commission uses, complementing the computational threshold of 10^25 FLOPs set in Article 51(2), to determine whether a GPAI model presents systemic risk.",
    sections: [
      {
        title: "Evaluation Criteria",
        preamble: "For the purpose of determining that a general-purpose AI model has capabilities or an impact equivalent to those set out in Article 51(1), point (a), the Commission shall take into account the following criteria:",
        items: [
          "(a) the number of parameters of the model;",
          "(b) the quality or size of the data set, for example measured through tokens;",
          "(c) the amount of compute used for training the model, measured in floating point operations or indicated by a combination of other variables such as estimated cost of training, estimated time required for the training, or estimated energy consumption for the training;",
          "(d) the input and output modalities of the model, such as text to text (large language models), text to image, multi-modality, and the state of the art thresholds for determining high-impact capabilities for each modality, and the specific type of the inputs and outputs (e.g. biological sequences);",
          "(e) the benchmarks and evaluations of capabilities of the model, including considering the number of tasks without additional training, adaptability to learn new, distinct tasks, its level of autonomy and scalability, the tools it has access to;",
          "(f) whether it has a high impact on the internal market due to its reach, which shall be presumed when it has been made available to at least 10 000 registered business users established in the Union;",
          "(g) the number of registered end users."
        ]
      }
    ]
  }
];
